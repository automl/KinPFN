{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "from kinpfn.priors import Batch\n",
    "from kinpfn.model import KINPFN\n",
    "\n",
    "\n",
    "from sklearn.mixture import BayesianGaussianMixture, GaussianMixture\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "def set_seed(seed=123):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_size(val_set_dir):\n",
    "    dataset_size = 0\n",
    "    for subdir, _, files in os.walk(val_set_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\"):\n",
    "                dataset_size += 1\n",
    "    return dataset_size\n",
    "\n",
    "\n",
    "def get_batch_testing_folding_times(val_set_dir, seq_len=100, num_features=1, **kwargs):\n",
    "\n",
    "    dataset_size = get_dataset_size(val_set_dir)\n",
    "\n",
    "    x = torch.zeros(seq_len, dataset_size, num_features)\n",
    "    y = torch.zeros(seq_len, dataset_size)\n",
    "\n",
    "    batch_index = 0\n",
    "    length_order = []\n",
    "    file_names_in_order = []\n",
    "    for subdir, _, files in os.walk(val_set_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\"):\n",
    "                path = os.path.join(subdir, file)\n",
    "                data = pl.read_csv(\n",
    "                    path,\n",
    "                    has_header=False,\n",
    "                    columns=[2, 4],\n",
    "                    n_rows=seq_len,\n",
    "                )\n",
    "\n",
    "                folding_times = data[\"column_3\"].to_numpy()\n",
    "                sequence = data[\"column_5\"][0]\n",
    "                length_order.append(len(sequence))\n",
    "                file_names_in_order.append(file)\n",
    "                sorted_folding_times = np.sort(folding_times)\n",
    "\n",
    "                # Filter out points where x > 10^15 and x < 10^-6\n",
    "                valid_indices = (sorted_folding_times <= 10**15) & (\n",
    "                    sorted_folding_times >= 10**-6\n",
    "                )\n",
    "                sorted_folding_times = sorted_folding_times[valid_indices]\n",
    "\n",
    "                # Adjust the sequence length by sampling\n",
    "                current_seq_len = len(sorted_folding_times)\n",
    "                if current_seq_len <= 0:\n",
    "                    continue\n",
    "\n",
    "                if current_seq_len < seq_len:\n",
    "                    # Repeat the sorted_folding_times and cdf to match the sequence length (Oversampling)\n",
    "                    repeat_factor = seq_len // current_seq_len + 1\n",
    "                    sorted_folding_times = np.tile(sorted_folding_times, repeat_factor)[\n",
    "                        :seq_len\n",
    "                    ]\n",
    "                else:\n",
    "                    sorted_folding_times = sorted_folding_times[:seq_len]\n",
    "\n",
    "                x[:, batch_index, 0] = torch.tensor(np.zeros(seq_len))\n",
    "                y[:, batch_index] = torch.tensor(sorted_folding_times)\n",
    "                batch_index += 1\n",
    "\n",
    "    y = torch.log10(y)\n",
    "    return Batch(x=x, y=y, target_y=y), length_order, file_names_in_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../../../../models/final_kinpfn_model_1400_1000_1000_86_50_2.5588748050825984e-05_256_4_512_8_0.0_0.0.pt\"\n",
    "\n",
    "kinpfn = KINPFN(\n",
    "    model_path=model_path,\n",
    ")\n",
    "trained_model = kinpfn.model\n",
    "\n",
    "if trained_model is not None:\n",
    "    print(\"Load trained model!\")\n",
    "else:\n",
    "    print(\"No trained model found!\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_lengths_and_losses(mean_losses, std_losses, bin_ranges):\n",
    "    grouped_mean_losses = defaultdict(list)\n",
    "    grouped_std_losses = defaultdict(list)\n",
    "\n",
    "    for length, loss in mean_losses.items():\n",
    "        for bin_key in bin_ranges:\n",
    "            if bin_key[0] <= length <= bin_key[1]:\n",
    "                grouped_mean_losses[bin_key].append(loss)\n",
    "                grouped_std_losses[bin_key].append(std_losses[length])\n",
    "                break\n",
    "\n",
    "    grouped_mean_losses = {\n",
    "        key: torch.mean(torch.tensor(val)) for key, val in grouped_mean_losses.items()\n",
    "    }\n",
    "    grouped_std_losses = {\n",
    "        key: torch.sqrt(torch.sum(torch.tensor(val) ** 2) / len(val))\n",
    "        for key, val in grouped_std_losses.items()\n",
    "    }\n",
    "\n",
    "    return grouped_mean_losses, grouped_std_losses\n",
    "\n",
    "\n",
    "def plot_losses(\n",
    "    grouped_nll_losses,\n",
    "    grouped_std_nll_losses,\n",
    "    grouped_mae_losses,\n",
    "    grouped_std_mae_losses,\n",
    "):\n",
    "    fontsize = 25\n",
    "    labelsize = 30\n",
    "\n",
    "    lengths = sorted(grouped_nll_losses.keys(), key=lambda x: x[0])\n",
    "    nll_values = [grouped_nll_losses[length] for length in lengths]\n",
    "    nll_stds = [grouped_std_nll_losses[length] for length in lengths]\n",
    "    mae_values = [grouped_mae_losses[length] for length in lengths]\n",
    "    mae_stds = [grouped_std_mae_losses[length] for length in lengths]\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(27, 11))\n",
    "    fig.set_dpi(300)\n",
    "\n",
    "    bar_width = 0.35\n",
    "    index = np.arange(len(lengths))\n",
    "\n",
    "    ax1.bar(\n",
    "        index,\n",
    "        nll_values,\n",
    "        bar_width,\n",
    "        yerr=nll_stds,\n",
    "        capsize=5,\n",
    "        label=\"Mean NLL incl. Std.\",\n",
    "        color=\"darkred\",\n",
    "        zorder=-10,\n",
    "    )\n",
    "    ax1.set_xlabel(\"RNA Sequence Length Ranges\", fontsize=labelsize)\n",
    "    ax1.set_ylabel(\"Mean NLL\", color=\"darkred\", fontsize=labelsize)\n",
    "    ax1.tick_params(axis=\"y\", labelcolor=\"darkred\", labelsize=fontsize)\n",
    "    ax1.tick_params(axis=\"x\", labelsize=fontsize)\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.bar(\n",
    "        index + bar_width,\n",
    "        mae_values,\n",
    "        bar_width,\n",
    "        yerr=mae_stds,\n",
    "        capsize=5,\n",
    "        label=\"MAE incl. Std.\",\n",
    "        color=\"steelblue\",\n",
    "        zorder=-10,\n",
    "    )\n",
    "    ax2.set_ylabel(\"MAE\", color=\"steelblue\", fontsize=labelsize)\n",
    "    ax2.tick_params(axis=\"y\", labelcolor=\"steelblue\", labelsize=fontsize)\n",
    "    legend1 = ax1.legend(loc=\"upper left\", fontsize=fontsize)\n",
    "    legend1.set_zorder(10)\n",
    "    ax1.add_artist(legend1)\n",
    "    legend2 = ax2.legend(loc=\"upper right\", fontsize=fontsize)\n",
    "    legend2.set_zorder(10)\n",
    "    ax2.add_artist(legend2)\n",
    "\n",
    "    plt.xticks(\n",
    "        index + bar_width / 2, [f\"{length[0]}-{length[1]}\" for length in lengths]\n",
    "    )\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close(\"all\")\n",
    "\n",
    "\n",
    "def model_testing_losses(trained_model):\n",
    "    seed = 75342\n",
    "    print(f\"Seed: {seed}\")\n",
    "    set_seed(seed=seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    seq_len = 1000\n",
    "    training_points = [25]\n",
    "\n",
    "    val_set_dir = \"../../../../kinpfn_testing_set\"\n",
    "\n",
    "    batch, length_order, file_names_in_order = get_batch_testing_folding_times(\n",
    "        val_set_dir=val_set_dir, seq_len=seq_len\n",
    "    )\n",
    "    dataset_size = get_dataset_size(val_set_dir)\n",
    "    print(f\"Dataset Size: {dataset_size}\")\n",
    "\n",
    "    x = batch.x\n",
    "    y_folding_times = batch.y\n",
    "    target_y_folding_times = batch.target_y\n",
    "\n",
    "    indices = list(range(dataset_size))\n",
    "\n",
    "    for training_point in training_points:\n",
    "        print(f\"Training Point: {training_point}\")\n",
    "\n",
    "        nll_losses_per_length = defaultdict(list)\n",
    "        mae_losses_per_length = defaultdict(list)\n",
    "\n",
    "        for i in indices:\n",
    "            batch_index = i\n",
    "            length = length_order[batch_index]\n",
    "\n",
    "            train_indices = torch.randperm(seq_len)[:training_point]\n",
    "            test_indices = ~train_indices\n",
    "\n",
    "            # Create the training and test data\n",
    "            train_x = x[train_indices, batch_index]\n",
    "            train_y_folding_times = y_folding_times[train_indices, batch_index]\n",
    "\n",
    "            test_x = x[:, batch_index]\n",
    "            test_y_folding_times = y_folding_times[:, batch_index]\n",
    "\n",
    "            train_x = train_x.to(device)\n",
    "            train_y_folding_times = train_y_folding_times.to(device)\n",
    "            test_x = test_x.to(device)\n",
    "            test_y_folding_times = test_y_folding_times.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # we add our batch dimension, as our transformer always expects that\n",
    "                logits = trained_model(\n",
    "                    train_x[:, None], train_y_folding_times[:, None], test_x[:, None]\n",
    "                )\n",
    "\n",
    "            ### CALCULATE GROUND TRUTH CDF WHICH WE WANT TO PREDICT\n",
    "            ground_truth_sorted_folding_times, _ = torch.sort(test_y_folding_times)\n",
    "            ground_truth_cdf = torch.arange(\n",
    "                1, len(ground_truth_sorted_folding_times) + 1\n",
    "            ) / len(ground_truth_sorted_folding_times)\n",
    "\n",
    "            test_y_folding_times_sorted, _ = torch.sort(test_y_folding_times)\n",
    "\n",
    "            ### CDF FUNCTION\n",
    "            pred_cdf_original = (\n",
    "                trained_model.criterion.cdf(logits, test_y_folding_times_sorted)\n",
    "            )[0][0]\n",
    "\n",
    "            # MAE\n",
    "            single_absolute_error = np.abs(pred_cdf_original - ground_truth_cdf)\n",
    "            mae = single_absolute_error.mean()\n",
    "            mae_losses_per_length[length].append(mae)\n",
    "\n",
    "            # NLL\n",
    "            nll_loss = trained_model.criterion.forward(\n",
    "                logits=logits, y=test_y_folding_times_sorted\n",
    "            )\n",
    "            mean_nll_loss = nll_loss.mean()\n",
    "            nll_losses_per_length[length].append(mean_nll_loss)\n",
    "\n",
    "        mean_nll_per_length = {\n",
    "            length: torch.mean(torch.stack(nlls))\n",
    "            for length, nlls in nll_losses_per_length.items()\n",
    "        }\n",
    "        std_nll_per_length = {\n",
    "            length: torch.std(torch.stack(nlls)) if len(nlls) > 1 else torch.tensor(0.0)\n",
    "            for length, nlls in nll_losses_per_length.items()\n",
    "        }\n",
    "\n",
    "        mean_mae_per_length = {\n",
    "            length: torch.mean(torch.stack(maes))\n",
    "            for length, maes in mae_losses_per_length.items()\n",
    "        }\n",
    "        std_mae_per_length = {\n",
    "            length: torch.std(torch.stack(maes)) if len(maes) > 1 else torch.tensor(0.0)\n",
    "            for length, maes in mae_losses_per_length.items()\n",
    "        }\n",
    "        bin_ranges = [\n",
    "            (15, 19),\n",
    "            (20, 29),\n",
    "            (30, 39),\n",
    "            (40, 49),\n",
    "            (50, 59),\n",
    "            (60, 69),\n",
    "            (70, 79),\n",
    "            (80, 89),\n",
    "            (90, 99),\n",
    "            (100, 109),\n",
    "            (110, 119),\n",
    "            (120, 129),\n",
    "            (130, 139),\n",
    "            (140, 147),\n",
    "        ]\n",
    "        grouped_nll_losses, grouped_std_nll_losses = group_lengths_and_losses(\n",
    "            mean_nll_per_length, std_nll_per_length, bin_ranges=bin_ranges\n",
    "        )\n",
    "        grouped_mae_losses, grouped_std_mae_losses = group_lengths_and_losses(\n",
    "            mean_mae_per_length, std_mae_per_length, bin_ranges=bin_ranges\n",
    "        )\n",
    "\n",
    "        plot_losses(\n",
    "            grouped_nll_losses,\n",
    "            grouped_std_nll_losses,\n",
    "            grouped_mae_losses,\n",
    "            grouped_std_mae_losses,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the losses of the model through various RNA sequence length ranges on the testing set\n",
    "#model_testing_losses(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_testing_losses_kde():\n",
    "    seed = 75342\n",
    "    print(f\"Seed: {seed}\")\n",
    "    set_seed(seed=seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    seq_len = 1000\n",
    "    training_points = [25]\n",
    "\n",
    "    val_set_dir = \"../../../../kinpfn_testing_set\"\n",
    "\n",
    "    batch, length_order, file_names_in_order = get_batch_testing_folding_times(\n",
    "        val_set_dir=val_set_dir, seq_len=seq_len\n",
    "    )\n",
    "    dataset_size = get_dataset_size(val_set_dir)\n",
    "    print(f\"Dataset Size: {dataset_size}\")\n",
    "\n",
    "    x = batch.x\n",
    "    y_folding_times = batch.y\n",
    "    target_y_folding_times = batch.target_y\n",
    "\n",
    "    indices = list(range(dataset_size))\n",
    "\n",
    "    for training_point in training_points:\n",
    "        print(f\"Training Point: {training_point}\")\n",
    "\n",
    "        nll_losses_per_length = defaultdict(list)\n",
    "        mae_losses_per_length = defaultdict(list)\n",
    "\n",
    "        for i in indices:\n",
    "            batch_index = i\n",
    "            length = length_order[batch_index]\n",
    "\n",
    "            train_indices = torch.randperm(seq_len)[:training_point]\n",
    "            test_indices = ~train_indices\n",
    "\n",
    "            # Create the training and test data\n",
    "            train_x = x[train_indices, batch_index]\n",
    "            train_y_folding_times = y_folding_times[train_indices, batch_index]\n",
    "\n",
    "            test_x = x[:, batch_index]\n",
    "            test_y_folding_times = y_folding_times[:, batch_index]\n",
    "\n",
    "            train_x = train_x.to(device)\n",
    "            train_y_folding_times = train_y_folding_times.to(device)\n",
    "            test_x = test_x.to(device)\n",
    "            test_y_folding_times = test_y_folding_times.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # we add our batch dimension, as our transformer always expects that\n",
    "                logits = trained_model(\n",
    "                    train_x[:, None], train_y_folding_times[:, None], test_x[:, None]\n",
    "                )\n",
    "\n",
    "            ### CALCULATE GROUND TRUTH CDF WHICH WE WANT TO PREDICT\n",
    "            ground_truth_sorted_folding_times, _ = torch.sort(test_y_folding_times)\n",
    "            ground_truth_cdf = torch.arange(\n",
    "                1, len(ground_truth_sorted_folding_times) + 1\n",
    "            ) / len(ground_truth_sorted_folding_times)\n",
    "\n",
    "            test_y_folding_times_sorted, _ = torch.sort(test_y_folding_times)\n",
    "\n",
    "            ### CDF FUNCTION\n",
    "            # pred_cdf_original = (\n",
    "            #     trained_model.criterion.cdf(logits, test_y_folding_times_sorted)\n",
    "            # )[0][0]\n",
    "\n",
    "            # # MAE\n",
    "            # single_absolute_error = np.abs(pred_cdf_original - ground_truth_cdf)\n",
    "            # mae = single_absolute_error.mean()\n",
    "            # mae_losses_per_length[length].append(mae)\n",
    "\n",
    "            # # NLL\n",
    "            # nll_loss = trained_model.criterion.forward(\n",
    "            #     logits=logits, y=test_y_folding_times_sorted\n",
    "            # )\n",
    "            # mean_nll_loss = nll_loss.mean()\n",
    "            # nll_losses_per_length[length].append(mean_nll_loss)\n",
    "\n",
    "\n",
    "            # KDE MAE and NLL\n",
    "            kde_train_y_folding_times = train_y_folding_times.reshape(-1, 1).cpu().numpy()\n",
    "            kde = KernelDensity(kernel='gaussian', bandwidth=0.3520031472796679).fit(kde_train_y_folding_times)\n",
    "            kde_test_y_folding_times_sorted = test_y_folding_times_sorted.reshape(-1, 1)\n",
    "            kde_pdf = np.exp(kde.score_samples(kde_test_y_folding_times_sorted))\n",
    "            kde_cdf = np.cumsum(kde_pdf) / np.sum(kde_pdf)\n",
    "            kde_mae = np.abs(kde_cdf - ground_truth_cdf.cpu().numpy()).mean()\n",
    "            # to tensor\n",
    "            kde_mae = torch.tensor(kde_mae)\n",
    "            mae_losses_per_length[length].append(kde_mae)\n",
    "\n",
    "\n",
    "            kde_nll = -np.mean(kde.score_samples(kde_test_y_folding_times_sorted))\n",
    "            kde_nll = torch.tensor(kde_nll)\n",
    "            nll_losses_per_length[length].append(kde_nll)\n",
    "\n",
    "\n",
    "\n",
    "        mean_nll_per_length = {\n",
    "            length: torch.mean(torch.stack(nlls))\n",
    "            for length, nlls in nll_losses_per_length.items()\n",
    "        }\n",
    "        std_nll_per_length = {\n",
    "            length: torch.std(torch.stack(nlls)) if len(nlls) > 1 else torch.tensor(0.0)\n",
    "            for length, nlls in nll_losses_per_length.items()\n",
    "        }\n",
    "\n",
    "        mean_mae_per_length = {\n",
    "            length: torch.mean(torch.stack(maes))\n",
    "            for length, maes in mae_losses_per_length.items()\n",
    "        }\n",
    "        std_mae_per_length = {\n",
    "            length: torch.std(torch.stack(maes)) if len(maes) > 1 else torch.tensor(0.0)\n",
    "            for length, maes in mae_losses_per_length.items()\n",
    "        }\n",
    "        bin_ranges = [\n",
    "            (15, 19),\n",
    "            (20, 29),\n",
    "            (30, 39),\n",
    "            (40, 49),\n",
    "            (50, 59),\n",
    "            (60, 69),\n",
    "            (70, 79),\n",
    "            (80, 89),\n",
    "            (90, 99),\n",
    "            (100, 109),\n",
    "            (110, 119),\n",
    "            (120, 129),\n",
    "            (130, 139),\n",
    "            (140, 147),\n",
    "        ]\n",
    "        grouped_nll_losses, grouped_std_nll_losses = group_lengths_and_losses(\n",
    "            mean_nll_per_length, std_nll_per_length, bin_ranges=bin_ranges\n",
    "        )\n",
    "        grouped_mae_losses, grouped_std_mae_losses = group_lengths_and_losses(\n",
    "            mean_mae_per_length, std_mae_per_length, bin_ranges=bin_ranges\n",
    "        )\n",
    "\n",
    "        plot_losses(\n",
    "            grouped_nll_losses,\n",
    "            grouped_std_nll_losses,\n",
    "            grouped_mae_losses,\n",
    "            grouped_std_mae_losses,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_testing_losses_kde()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_lengths_and_losses_kde_kinpfn(mean_losses, std_losses, bin_ranges):\n",
    "    grouped_mean_losses = defaultdict(list)\n",
    "    grouped_std_losses = defaultdict(list)\n",
    "\n",
    "    for length, loss in mean_losses.items():\n",
    "        for bin_key in bin_ranges:\n",
    "            if bin_key[0] <= length <= bin_key[1]:\n",
    "                grouped_mean_losses[bin_key].append(loss)\n",
    "                grouped_std_losses[bin_key].append(std_losses[length])\n",
    "                break\n",
    "\n",
    "    grouped_mean_losses = {\n",
    "        key: torch.mean(torch.tensor(val)) for key, val in grouped_mean_losses.items()\n",
    "    }\n",
    "    grouped_std_losses = {\n",
    "        key: torch.sqrt(torch.sum(torch.tensor(val) ** 2) / len(val))\n",
    "        for key, val in grouped_std_losses.items()\n",
    "    }\n",
    "\n",
    "    return grouped_mean_losses, grouped_std_losses\n",
    "\n",
    "\n",
    "def plot_losses_kde_kinpfn(\n",
    "    kinpfn_grouped_losses,\n",
    "    kinpfn_grouped_std_losses,\n",
    "    kde_grouped_losses,\n",
    "    kde_grouped_std_losses,\n",
    "    lossType=\"NLL\",\n",
    "):\n",
    "    fontsize = 25\n",
    "    labelsize = 30\n",
    "\n",
    "    lengths = sorted(kinpfn_grouped_losses.keys(), key=lambda x: x[0])\n",
    "    kinpfn_values = [kinpfn_grouped_losses[length] for length in lengths]\n",
    "    kinpfn_stds = [kinpfn_grouped_std_losses[length] for length in lengths]\n",
    "    kde_values = [kde_grouped_losses[length] for length in lengths]\n",
    "    kde_stds = [kde_grouped_std_losses[length] for length in lengths]\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(27, 11))\n",
    "    fig.set_dpi(300)\n",
    "\n",
    "    bar_width = 0.35\n",
    "    index = np.arange(len(lengths))\n",
    "\n",
    "    ax1.bar(\n",
    "        index,\n",
    "        kinpfn_values,\n",
    "        bar_width,\n",
    "        yerr=kinpfn_stds,\n",
    "        capsize=5,\n",
    "        label=f\"KinPFN {lossType} incl. Std.\",\n",
    "        color=\"darkred\",\n",
    "        zorder=-10,\n",
    "    )\n",
    "    ax1.set_xlabel(\"RNA Sequence Length Ranges\", fontsize=labelsize)\n",
    "    ax1.set_ylabel('KinPFN' + lossType, color=\"darkred\", fontsize=labelsize)\n",
    "    ax1.tick_params(axis=\"y\", labelcolor=\"darkred\", labelsize=fontsize)\n",
    "    ax1.tick_params(axis=\"x\", labelsize=fontsize)\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.bar(\n",
    "        index + bar_width,\n",
    "        kde_values,\n",
    "        bar_width,\n",
    "        yerr=kde_stds,\n",
    "        capsize=5,\n",
    "        label=f\"KDE {lossType} incl. Std.\",\n",
    "        color=\"steelblue\",\n",
    "        zorder=-10,\n",
    "    )\n",
    "    ax2.set_ylabel('KDE' + lossType, color=\"steelblue\", fontsize=labelsize)\n",
    "    ax2.tick_params(axis=\"y\", labelcolor=\"steelblue\", labelsize=fontsize)\n",
    "    legend1 = ax1.legend(loc=\"upper left\", fontsize=fontsize)\n",
    "    legend1.set_zorder(10)\n",
    "    ax1.add_artist(legend1)\n",
    "    legend2 = ax2.legend(loc=\"upper right\", fontsize=fontsize)\n",
    "    legend2.set_zorder(10)\n",
    "    ax2.add_artist(legend2)\n",
    "\n",
    "    plt.xticks(\n",
    "        index + bar_width / 2, [f\"{length[0]}-{length[1]}\" for length in lengths]\n",
    "    )\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close(\"all\")\n",
    "\n",
    "\n",
    "def model_testing_losses_kde_kinpfn(trained_model):\n",
    "    seed = 75342\n",
    "    print(f\"Seed: {seed}\")\n",
    "    set_seed(seed=seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    seq_len = 1000\n",
    "    training_points = [25]\n",
    "\n",
    "    val_set_dir = \"../../../../kinpfn_testing_set\"\n",
    "\n",
    "    batch, length_order, file_names_in_order = get_batch_testing_folding_times(\n",
    "        val_set_dir=val_set_dir, seq_len=seq_len\n",
    "    )\n",
    "    dataset_size = get_dataset_size(val_set_dir)\n",
    "    print(f\"Dataset Size: {dataset_size}\")\n",
    "\n",
    "    x = batch.x\n",
    "    y_folding_times = batch.y\n",
    "    target_y_folding_times = batch.target_y\n",
    "\n",
    "    indices = list(range(dataset_size))\n",
    "\n",
    "    for training_point in training_points:\n",
    "        print(f\"Training Point: {training_point}\")\n",
    "\n",
    "        nll_losses_per_length = defaultdict(list)\n",
    "        mae_losses_per_length = defaultdict(list)\n",
    "\n",
    "        kde_nll_losses_per_length = defaultdict(list)\n",
    "        kde_mae_losses_per_length = defaultdict(list)\n",
    "\n",
    "        for i in indices:\n",
    "            batch_index = i\n",
    "            length = length_order[batch_index]\n",
    "\n",
    "            train_indices = torch.randperm(seq_len)[:training_point]\n",
    "            test_indices = ~train_indices\n",
    "\n",
    "            # Create the training and test data\n",
    "            train_x = x[train_indices, batch_index]\n",
    "            train_y_folding_times = y_folding_times[train_indices, batch_index]\n",
    "\n",
    "            test_x = x[:, batch_index]\n",
    "            test_y_folding_times = y_folding_times[:, batch_index]\n",
    "\n",
    "            train_x = train_x.to(device)\n",
    "            train_y_folding_times = train_y_folding_times.to(device)\n",
    "            test_x = test_x.to(device)\n",
    "            test_y_folding_times = test_y_folding_times.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # we add our batch dimension, as our transformer always expects that\n",
    "                logits = trained_model(\n",
    "                    train_x[:, None], train_y_folding_times[:, None], test_x[:, None]\n",
    "                )\n",
    "\n",
    "            ### CALCULATE GROUND TRUTH CDF WHICH WE WANT TO PREDICT\n",
    "            ground_truth_sorted_folding_times, _ = torch.sort(test_y_folding_times)\n",
    "            ground_truth_cdf = torch.arange(\n",
    "                1, len(ground_truth_sorted_folding_times) + 1\n",
    "            ) / len(ground_truth_sorted_folding_times)\n",
    "\n",
    "            test_y_folding_times_sorted, _ = torch.sort(test_y_folding_times)\n",
    "\n",
    "            ### CDF FUNCTION\n",
    "            pred_cdf_original = (\n",
    "                trained_model.criterion.cdf(logits, test_y_folding_times_sorted)\n",
    "            )[0][0]\n",
    "\n",
    "            # MAE\n",
    "            single_absolute_error = np.abs(pred_cdf_original - ground_truth_cdf)\n",
    "            mae = single_absolute_error.mean()\n",
    "            mae_losses_per_length[length].append(mae)\n",
    "\n",
    "            # NLL\n",
    "            nll_loss = trained_model.criterion.forward(\n",
    "                logits=logits, y=test_y_folding_times_sorted\n",
    "            )\n",
    "            mean_nll_loss = nll_loss.mean()\n",
    "            nll_losses_per_length[length].append(mean_nll_loss)\n",
    "\n",
    "\n",
    "\n",
    "            # KDE MAE and NLL\n",
    "            kde_train_y_folding_times = train_y_folding_times.reshape(-1, 1).cpu().numpy()\n",
    "            kde = KernelDensity(kernel='gaussian', bandwidth=0.3520031472796679).fit(kde_train_y_folding_times)\n",
    "            kde_test_y_folding_times_sorted = test_y_folding_times_sorted.reshape(-1, 1)\n",
    "            kde_pdf = np.exp(kde.score_samples(kde_test_y_folding_times_sorted))\n",
    "            kde_cdf = np.cumsum(kde_pdf) / np.sum(kde_pdf)\n",
    "            kde_mae = np.abs(kde_cdf - ground_truth_cdf.cpu().numpy()).mean()\n",
    "            # to tensor\n",
    "            kde_mae = torch.tensor(kde_mae)\n",
    "            kde_mae_losses_per_length[length].append(kde_mae)\n",
    "\n",
    "\n",
    "            kde_nll = -np.mean(kde.score_samples(kde_test_y_folding_times_sorted))\n",
    "            kde_nll = torch.tensor(kde_nll)\n",
    "            kde_nll_losses_per_length[length].append(kde_nll)\n",
    "\n",
    "        mean_nll_per_length = {\n",
    "            length: torch.mean(torch.stack(nlls))\n",
    "            for length, nlls in nll_losses_per_length.items()\n",
    "        }\n",
    "        std_nll_per_length = {\n",
    "            length: torch.std(torch.stack(nlls)) if len(nlls) > 1 else torch.tensor(0.0)\n",
    "            for length, nlls in nll_losses_per_length.items()\n",
    "        }\n",
    "\n",
    "        kde_mean_nll_per_length = {\n",
    "            length: torch.mean(torch.stack(nlls))\n",
    "            for length, nlls in kde_nll_losses_per_length.items()\n",
    "        }\n",
    "        kde_std_nll_per_length = {\n",
    "            length: torch.std(torch.stack(nlls)) if len(nlls) > 1 else torch.tensor(0.0)\n",
    "            for length, nlls in kde_nll_losses_per_length.items()\n",
    "        }\n",
    "\n",
    "        mean_mae_per_length = {\n",
    "            length: torch.mean(torch.stack(maes))\n",
    "            for length, maes in mae_losses_per_length.items()\n",
    "        }\n",
    "        std_mae_per_length = {\n",
    "            length: torch.std(torch.stack(maes)) if len(maes) > 1 else torch.tensor(0.0)\n",
    "            for length, maes in mae_losses_per_length.items()\n",
    "        }\n",
    "\n",
    "        kde_mean_mae_per_length = {\n",
    "            length: torch.mean(torch.stack(maes))\n",
    "            for length, maes in kde_mae_losses_per_length.items()\n",
    "        }\n",
    "        kde_std_mae_per_length = {\n",
    "            length: torch.std(torch.stack(maes)) if len(maes) > 1 else torch.tensor(0.0)\n",
    "            for length, maes in kde_mae_losses_per_length.items()\n",
    "        }\n",
    "\n",
    "        bin_ranges = [\n",
    "            (15, 19),\n",
    "            (20, 29),\n",
    "            (30, 39),\n",
    "            (40, 49),\n",
    "            (50, 59),\n",
    "            (60, 69),\n",
    "            (70, 79),\n",
    "            (80, 89),\n",
    "            (90, 99),\n",
    "            (100, 109),\n",
    "            (110, 119),\n",
    "            (120, 129),\n",
    "            (130, 139),\n",
    "            (140, 147),\n",
    "        ]\n",
    "        grouped_nll_losses, grouped_std_nll_losses = group_lengths_and_losses_kde_kinpfn(\n",
    "            mean_nll_per_length, std_nll_per_length, bin_ranges=bin_ranges\n",
    "        )\n",
    "        grouped_mae_losses, grouped_std_mae_losses = group_lengths_and_losses_kde_kinpfn(\n",
    "            mean_mae_per_length, std_mae_per_length, bin_ranges=bin_ranges\n",
    "        )\n",
    "\n",
    "        kde_grouped_nll_losses, kde_grouped_std_nll_losses = group_lengths_and_losses_kde_kinpfn(\n",
    "            kde_mean_nll_per_length, kde_std_nll_per_length, bin_ranges=bin_ranges\n",
    "        )\n",
    "        kde_grouped_mae_losses, kde_grouped_std_mae_losses = group_lengths_and_losses_kde_kinpfn(\n",
    "            kde_mean_mae_per_length, kde_std_mae_per_length, bin_ranges=bin_ranges\n",
    "        )\n",
    "\n",
    "        plot_losses_kde_kinpfn(\n",
    "            grouped_nll_losses,\n",
    "            grouped_std_nll_losses,\n",
    "            kde_grouped_nll_losses,\n",
    "            kde_grouped_std_nll_losses,\n",
    "        )\n",
    "\n",
    "        plot_losses_kde_kinpfn(\n",
    "            grouped_mae_losses,\n",
    "            grouped_std_mae_losses,\n",
    "            kde_grouped_mae_losses,\n",
    "            kde_grouped_std_mae_losses,\n",
    "            lossType=\"MAE\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_testing_losses_kde_kinpfn(trained_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kinpfn_test_iclr_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
